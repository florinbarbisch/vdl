{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook\n",
    "\n",
    "In diesem Notebook ist die Codebase beschrieben.\n",
    "\n",
    "Das Training (5-Fold Cross-Validation) kann durch folgende Befehle ausgef√ºhrt werden:\n",
    "```bash\n",
    "python src/train.py --model show_tell --checkpoint_dir show_tell_fold0 --eval_fold 0 --epochs 10\n",
    "python src/train.py --model show_tell --checkpoint_dir show_tell_fold1 --eval_fold 1 --epochs 10\n",
    "python src/train.py --model show_tell --checkpoint_dir show_tell_fold2 --eval_fold 2 --epochs 10\n",
    "python src/train.py --model show_tell --checkpoint_dir show_tell_fold3 --eval_fold 3 --epochs 10\n",
    "python src/train.py --model show_tell --checkpoint_dir show_tell_fold4 --eval_fold 4 --epochs 10\n",
    "\n",
    "python src/train.py --model show_attend_tell --checkpoint_dir show_attend_tell_fold0 --eval_fold 0 --epochs 10\n",
    "python src/train.py --model show_attend_tell --checkpoint_dir show_attend_tell_fold1 --eval_fold 1 --epochs 10\n",
    "python src/train.py --model show_attend_tell --checkpoint_dir show_attend_tell_fold2 --eval_fold 2 --epochs 10\n",
    "python src/train.py --model show_attend_tell --checkpoint_dir show_attend_tell_fold3 --eval_fold 3 --epochs 10\n",
    "python src/train.py --model show_attend_tell --checkpoint_dir show_attend_tell_fold4 --eval_fold 4 --epochs 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint artefacts generated during 5-fold cv trained using commands from above \n",
    "model_artefacts = {\n",
    "    \"show_tell\": {\n",
    "        0: \"model-show_tell_20250107_012408_fold0:v0\",\n",
    "        1: \"model-show_tell_20250107_014557_fold1:v0\",\n",
    "        2: \"model-show_tell_20250107_020657_fold2:v0\",\n",
    "        3: \"model-show_tell_20250107_022823_fold3:v0\",\n",
    "        4: \"model-show_tell_20250107_024856_fold4:v0\"\n",
    "    },\n",
    "    \"show_attend_tell\": {\n",
    "        0: \"model-show_attend_tell_20250107_030953_fold0:v0\",\n",
    "        1: \"model-show_attend_tell_20250107_035920_fold1:v0\",\n",
    "        2: \"model-show_attend_tell_20250107_044723_fold2:v0\",\n",
    "        3: \"model-show_attend_tell_20250107_053559_fold3:v0\",\n",
    "        4: \"model-show_attend_tell_20250107_062503_fold4:v0\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to skip the evaluation and just use results from evals already run, set this to True\n",
    "SKIP_EVAL = False\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating show_tell fold 0\n",
      "\n",
      "Evaluating show_tell fold 1\n",
      "\n",
      "Evaluating show_tell fold 2\n",
      "\n",
      "Evaluating show_tell fold 3\n",
      "\n",
      "Evaluating show_tell fold 4\n",
      "\n",
      "Evaluating show_attend_tell fold 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# evaluate each artefact using the following command\n",
    "# python eval.py --model [show_tell/show_attend_tell] --eval_fold [fold] --wandb_project image-captioning-comparison --wandb_artifact [artifact_name:version]\n",
    "if not SKIP_EVAL:\n",
    "    results = {}\n",
    "    for model_name, folds in model_artefacts.items():\n",
    "        for fold, artifact in folds.items():\n",
    "            if fold in results.get(model_name, {}):\n",
    "                print(f\"Skipping {model_name} fold {fold} as it is already evaluated.\")\n",
    "                continue\n",
    "            cmd = [sys.executable, \"eval.py\", \"--model\", model_name, \"--eval_fold\", str(fold), \"--wandb_project\", \"image-captioning-comparison\", \"--wandb_artifact\", artifact]\n",
    "            print(f\"\\nEvaluating {model_name} fold {fold}\")\n",
    "            result = subprocess.run(cmd, capture_output=True)\n",
    "            out = result.stdout.decode('utf-8')\n",
    "            err = result.stderr.decode('utf-8')\n",
    "\n",
    "            # Extract the run URL from the stdout\n",
    "            if \"https://wandb.ai/\" in err:\n",
    "                url_line = [line for line in err.splitlines() if (\"https://wandb.ai/\" in line and \"/runs/\" in line)]\n",
    "                if url_line:\n",
    "                    run_url = url_line[0].strip()\n",
    "                    run_id = run_url.split(\"/\")[-1]  # Get the last part of the URL\n",
    "                    results.setdefault(model_name, {})[fold] = run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'show_tell': {0: '2tg2yil9', 1: 'hngbhvxd'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beam_bleu4</th>\n",
       "      <th>beam_bleu2</th>\n",
       "      <th>_step</th>\n",
       "      <th>beam_bleu1</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>greedy_bleu4</th>\n",
       "      <th>greedy_bleu1</th>\n",
       "      <th>greedy_bleu2</th>\n",
       "      <th>beam_bleu3</th>\n",
       "      <th>greedy_bleu3</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.186993e-76</td>\n",
       "      <td>13.156025</td>\n",
       "      <td>0</td>\n",
       "      <td>35.193133</td>\n",
       "      <td>26.954806</td>\n",
       "      <td>4.842084e-153</td>\n",
       "      <td>29.284165</td>\n",
       "      <td>10.537078</td>\n",
       "      <td>4.609435</td>\n",
       "      <td>6.754901e-101</td>\n",
       "      <td>1.736245e+09</td>\n",
       "      <td>show_tell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.349674e+00</td>\n",
       "      <td>11.070336</td>\n",
       "      <td>0</td>\n",
       "      <td>26.583963</td>\n",
       "      <td>137.737707</td>\n",
       "      <td>2.395733e+00</td>\n",
       "      <td>26.274515</td>\n",
       "      <td>10.253199</td>\n",
       "      <td>4.918598</td>\n",
       "      <td>4.647314e+00</td>\n",
       "      <td>1.736243e+09</td>\n",
       "      <td>show_tell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     beam_bleu4  beam_bleu2  _step  beam_bleu1    _runtime   greedy_bleu4  \\\n",
       "0  1.186993e-76   13.156025      0   35.193133   26.954806  4.842084e-153   \n",
       "1  2.349674e+00   11.070336      0   26.583963  137.737707   2.395733e+00   \n",
       "\n",
       "   greedy_bleu1  greedy_bleu2  beam_bleu3   greedy_bleu3    _timestamp  \\\n",
       "0     29.284165     10.537078    4.609435  6.754901e-101  1.736245e+09   \n",
       "1     26.274515     10.253199    4.918598   4.647314e+00  1.736243e+09   \n",
       "\n",
       "       model  fold  \n",
       "0  show_tell     0  \n",
       "1  show_tell     1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "# Initialize an empty list to store logs\n",
    "all_logs = []\n",
    "\n",
    "# Iterate through the results to fetch logs for each model and fold\n",
    "for model_name, folds in results.items():\n",
    "    for fold, run_id in folds.items():\n",
    "        # run is specified by <entity>/<project>/<run_id>\n",
    "        run = api.run(f\"florin-barbisch/image-captioning-comparison/runs/{run_id}\")\n",
    "\n",
    "        # Fetch the logs for beam_bleu1\n",
    "        logs = run.history()\n",
    "        # Adding model and fold columns to the DataFrame\n",
    "        logs['model'] = model_name\n",
    "        logs['fold'] = fold\n",
    "        \n",
    "        # Append the logs to the list\n",
    "        all_logs.append(logs)\n",
    "\n",
    "# Concatenate all logs into one big DataFrame\n",
    "final_logs_df = pd.concat(all_logs, ignore_index=True)\n",
    "\n",
    "final_logs_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
